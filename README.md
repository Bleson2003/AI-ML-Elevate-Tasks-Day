🧹 Task 1: Data Cleaning & Preprocessing
🚀 AI & ML Internship
📌 Objective
The goal of this task is to understand and implement data cleaning and preprocessing techniques which are essential steps before building any machine learning model. This involves handling missing values, encoding categorical variables, detecting outliers, and normalizing features.

📁 Dataset
Dataset used: Titanic Dataset
The Titanic dataset contains information about the passengers aboard the ill-fated Titanic ship and is commonly used for data science and ML practice.

🛠 Tools Used
Python

Pandas

NumPy

Matplotlib

Seaborn

📊 Steps Implemented
Data Import & Exploration

Loaded the dataset using Pandas

Explored data types, missing values, and basic statistics

Handling Missing Values

Used mean/median imputation for numerical features

Mode imputation for categorical variables

Encoding Categorical Features

Applied One-Hot Encoding and Label Encoding based on feature type and relevance

Feature Scaling

Normalized numerical columns using MinMaxScaler and StandardScaler

Outlier Detection & Removal

Used boxplots to visualize and remove outliers

📷 Screenshots
(Optional: Add screenshots of your code output or plots here)

❓ Interview Questions Covered
Types of missing data

Handling categorical variables

Normalization vs. standardization

Outlier detection methods

Importance of preprocessing

One-hot encoding vs label encoding

Handling data imbalance

Impact of preprocessing on model accuracy

📎 Submission
Google Form Submission Link

🤝 Acknowledgments
Thanks to the organizers of the AI & ML Internship for providing this valuable learning opportunity.

![ai-,l](https://github.com/user-attachments/assets/d7b56db9-1741-4552-ae85-324f9ee983df)

